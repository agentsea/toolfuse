{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of the Weather Logger Agent\n",
    "\n",
    "In this notebook, we'll see how to write and use a very simple Weather Logger agent. It will support two operations: an observation that checks the current weather, and an action that logs the weather in a file. \n",
    "\n",
    "Let's start with various imports we need.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a file `.env` and put your OPEN_AI_KEY there.\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "OPEN_AI_KEY = os.environ.get('OPEN_AI_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import openai\n",
    "import json\n",
    "from toolfuse import Tool, action, observation\n",
    "\n",
    "openai.api_key = OPEN_AI_KEY\n",
    "client = openai.OpenAI(api_key=OPEN_AI_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define the Weather Logger Tool. It's a simple implementation of the `Tool` class, with two methods: `log` and `check`.\n",
    "\n",
    "`check` goes to `wttr.in` and returns the weather in a human-readable format. `log` takes any message and appends it to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherLogger(Tool):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.log_file = \"weather.txt\"\n",
    "\n",
    "    @action\n",
    "    def log(self, message: str):\n",
    "        \"\"\"Logs a message to the log file.\"\"\"\n",
    "        with open(self.log_file, \"a\") as file:\n",
    "            file.write(\"***\\n\" + message + \"\\n\")\n",
    "\n",
    "    @observation\n",
    "    def weather(self, location: str) -> str:\n",
    "        \"\"\"Checks the current weather from the internet using wttr.in.\"\"\"\n",
    "        weather_api_url = f\"http://wttr.in/{location}?format=%l:+%C+%t\"\n",
    "        try:\n",
    "            response = requests.get(weather_api_url)\n",
    "            return response.text\n",
    "        except requests.exceptions.HTTPError as err:\n",
    "            return f\"HTTP Error: {err}\"\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return f\"Error: Could not retrieve weather data. {e}\"\n",
    "        \n",
    "    def close(self):\n",
    "        \"\"\"Close the WeatherLogger tool and release any resources.\"\"\"\n",
    "        # Since there are no resources to release in this simple example, pass is used.\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the weather:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = WeatherLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paris: Partly cloudy +11째C'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = tool.weather(\"Paris\")\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***\n",
      "Paris: Partly cloudy +11째C\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tool.log(message)\n",
    "with open(tool.log_file, \"r\") as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it work? Super. However, we don't wrap the weather API call into a Tool just for the sake of it. \n",
    "\n",
    "We can now use it with AI. How? A Tool can export the list of supported actions and observations to a JSON schema and also execute actions from JSONs and dicts. \n",
    "\n",
    "Let's look at the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'log',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'message': {'type': 'string'}},\n",
       "   'required': ['message']},\n",
       "  'description': 'Logs a message to the log file.'},\n",
       " {'name': 'weather',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'location': {'type': 'string'}},\n",
       "   'required': ['location']},\n",
       "  'description': 'Checks the current weather from the internet using wttr.in.'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = tool.json_schema()\n",
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the schema lists all actions we have with their parameters and descriptions. \n",
    "\n",
    "Given this information, we can implement a simple scenario:\n",
    "\n",
    "* We inform the AI about the tools (in our case, `weather` and `log`) that it can use.\n",
    "* We give it a task to check and describe weather in a given city.\n",
    "* We start the loop: ask it for the next step, execute the next step, give it the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first. As you know, prompting is new programming, so a correct prompt is super important. Let's define the system prompt and the task for our little weather agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = f\"\"\"You are a helpful poetical AI. \n",
    "You can check the weather, write a short poem to describe it and log all of that. \n",
    "You have the following tools awailable to you: \n",
    "\n",
    "{schema}\n",
    "\n",
    "When you respond, always give a JSON with a correct tool called. For example:\n",
    "\n",
    "{{\"tool\": \"weather\", \"parameters\": {{\"location\": \"Thessaloniki\"}}}}\n",
    "\n",
    "{{\"tool\": \"log\", \"parameters\": {{\"message\": \"The weather is nice.\"}}}}\n",
    "\n",
    "Only answer with JSON. Avoid wrapping it in quotes.\n",
    "\"\"\"\n",
    "\n",
    "task = \"Check the weather in Paris, describe it, and log the result.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define a couple of helper functions. One will send a question to AI and return the response, while the other one will use this response to execute the next step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_ai(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        messages=messages,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    print(f\"Full response: {response}\")\n",
    "    assistant_reply = response.choices[0].message.content\n",
    "    print(f\"Actual reply: {assistant_reply}\")\n",
    "    return assistant_reply\n",
    "\n",
    "def execute_step(reply, tool):\n",
    "    jdict = json.loads(reply)\n",
    "    print(f\"Parsed JSON: {jdict}\")\n",
    "    action = tool.find_action(jdict['tool'])\n",
    "    print(f\"Found action: {action.name}\")\n",
    "    result = tool.use(action, **jdict['parameters'])\n",
    "    print(f\"Result: {result}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we prepare the first messages we'll send to the Completion OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "messages.append({\"role\": \"user\", \"content\": task})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, go! In the first loop, our little agent should suggest to check the weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full response: ChatCompletion(id='chatcmpl-99VnOohk6ZIC2eYU4KcOjiFTxQt5W', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\"tool\": \"weather\", \"parameters\": {\"location\": \"Paris\"}}', role='assistant', function_call=None, tool_calls=None))], created=1712054202, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_d986a8d1ba', usage=CompletionUsage(completion_tokens=15, prompt_tokens=134, total_tokens=149))\n",
      "Actual reply: {\"tool\": \"weather\", \"parameters\": {\"location\": \"Paris\"}}\n",
      "Parsed JSON: {'tool': 'weather', 'parameters': {'location': 'Paris'}}\n",
      "Found action: weather\n",
      "Result: Paris: Partly cloudy +11째C\n"
     ]
    }
   ],
   "source": [
    "reply = ask_ai(messages)\n",
    "messages.append({\"role\": \"assistant\", \"content\": reply})\n",
    "result = execute_step(reply, tool)\n",
    "messages.append({\"role\": \"user\", \"content\": result})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second loop, it gets the weather, comes up with a little poem and uses `log` tool to record it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full response: ChatCompletion(id='chatcmpl-99VnQsPQaKe8pnam7TipWUKnlrNSb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\"tool\": \"log\", \"parameters\": {\"message\": \"A sky of artists\\' delight, in Paris so fair,\\\\nPartly clad in cloudy attire, with a cool, gentle air,\\\\nEleven degrees holds the day in its embrace,\\\\nWhile sun and clouds in a dainty dance do chase.\"}}', role='assistant', function_call=None, tool_calls=None))], created=1712054204, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_e467c31c3d', usage=CompletionUsage(completion_tokens=65, prompt_tokens=165, total_tokens=230))\n",
      "Actual reply: {\"tool\": \"log\", \"parameters\": {\"message\": \"A sky of artists' delight, in Paris so fair,\\nPartly clad in cloudy attire, with a cool, gentle air,\\nEleven degrees holds the day in its embrace,\\nWhile sun and clouds in a dainty dance do chase.\"}}\n",
      "Parsed JSON: {'tool': 'log', 'parameters': {'message': \"A sky of artists' delight, in Paris so fair,\\nPartly clad in cloudy attire, with a cool, gentle air,\\nEleven degrees holds the day in its embrace,\\nWhile sun and clouds in a dainty dance do chase.\"}}\n",
      "Found action: log\n",
      "Result: None\n"
     ]
    }
   ],
   "source": [
    "reply = ask_ai(messages)\n",
    "messages.append({\"role\": \"assistant\", \"content\": reply})\n",
    "result = execute_step(reply, tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we are, with a beautiful poem about the weather in the city of your choice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***\n",
      "Paris: Partly cloudy +11째C\n",
      "***\n",
      "A sky of artists' delight, in Paris so fair,\n",
      "Partly clad in cloudy attire, with a cool, gentle air,\n",
      "Eleven degrees holds the day in its embrace,\n",
      "While sun and clouds in a dainty dance do chase.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(tool.log_file, \"r\") as file:\n",
    "    print(file.read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentdesk2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
